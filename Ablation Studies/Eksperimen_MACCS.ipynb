{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a258aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\toxpred\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna import Trial\n",
    "\n",
    "from math import sqrt\n",
    "from typing import Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mordred import Calculator, descriptors\n",
    "#import openbabel\n",
    "from openbabel import pybel\n",
    "from PyBioMed.PyMolecule.fingerprint import CalculatePubChemFingerprint,CalculateECFP2Fingerprint\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdchem import Atom\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, roc_curve, auc \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader as G_Loader \n",
    "from torch_geometric.nn import GCNConv, GATConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch_geometric.nn import BatchNorm\n",
    "\n",
    "\n",
    "# RDkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit import DataStructs\n",
    "\n",
    "# Pytorch and Pytorch Geometric\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F # activation function\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader as V_Loader # dataset management\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, roc_curve, auc \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# performances visualization \n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import statistics\n",
    "from prettytable import PrettyTable\n",
    "%run ./my_performances.ipynb \n",
    "\n",
    "\n",
    "#%run ./graph_feature.ipynb \n",
    "#%run ./dataset_processing.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c0aeb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the data fingerprint \n",
    "#=======================================================\n",
    "k=10\n",
    "final_clean_fingerp_train=[]\n",
    "final_clean_fingerp_val=[]\n",
    "for i in range(k):\n",
    "    final_clean_fingerp_train.append(np.load('final_clean_fingerp_train'+ str(i)+'.npy'))\n",
    "    final_clean_fingerp_val.append(np.load('final_clean_fingerp_val' +str(i)+'.npy'))\n",
    "\n",
    "final_clean_fingerp_test = np.load('final_clean_fingerp_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "238b6f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.load('train_indices.npy')\n",
    "val_idx = np.load('val_indices.npy')\n",
    "test_idx = np.load('test_indices.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "076a37ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the output label \n",
    "total_train_targets =[]\n",
    "total_validation_targets =[]\n",
    "total_test_targets=[]\n",
    "for i in range(k):\n",
    "    total_train_targets.append(np.load('total_train_targets'+ str(i)+'.npy'))\n",
    "    total_validation_targets.append(np.load('total_validation_targets' +str(i)+'.npy'))\n",
    "\n",
    "total_test_targets= np.load('total_test_targets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dae43bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader for training (vector data)\n",
    "#======================================================================================\n",
    "list_data_fingerp_train =[]\n",
    "list_data_fingerp_val =[]\n",
    "list_data_target_train =[]\n",
    "list_data_target_val =[]\n",
    "\n",
    "for data_train, data_val, tr_targets, val_targets in zip(final_clean_fingerp_train, final_clean_fingerp_val,total_train_targets, total_validation_targets):\n",
    "    train_loader = V_Loader(dataset = data_train, batch_size = 126)\n",
    "    val_loader = V_Loader(dataset = data_val, batch_size = 126)\n",
    "    \n",
    "    tr_target_loader = V_Loader(dataset = tr_targets, batch_size = 126)\n",
    "    val_target_loader =  V_Loader(dataset = val_targets, batch_size = 126)\n",
    "    \n",
    "    list_data_fingerp_train.append(train_loader)\n",
    "    list_data_fingerp_val.append(val_loader)\n",
    "    \n",
    "    list_data_target_train.append(tr_target_loader)\n",
    "    list_data_target_val.append(val_target_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1de45f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "#define the loss function \n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "027b6463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, roc_curve, auc \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# performances visualization \n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import statistics\n",
    "import math\n",
    "from prettytable import PrettyTable\n",
    "%run ./my_performances.ipynb \n",
    "\n",
    "\n",
    "def test_1(v_loaderB,v_target, combined_model):\n",
    "    combined_model.eval()\n",
    "    list_pred =[]\n",
    "    list_targets =[]\n",
    "    correct = 0\n",
    "    for data_X2, data_target in zip (v_loaderB,v_target):  # Iterate in batches over the training/test dataset.\n",
    "            out = combined_model(torch.tensor(data_X2, dtype=torch.float32))\n",
    "            out_1 = out[:,0]\n",
    "            \n",
    "            list_pred.append(out_1.item())\n",
    "            list_targets.append(data_target.item())\n",
    "    return list_pred, list_targets\n",
    "\n",
    "# used to count the train accuracy ,and validation accuracy when in the training mode \n",
    "def test(v_loaderB,target_v_loaderB, combined_model):\n",
    "    combined_model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data_X2, data_target in zip(v_loaderB,target_v_loaderB):  # Iterate in batches over the training/test dataset.\n",
    "            out = combined_model(torch.tensor(data_X2, dtype=torch.float32))\n",
    "            out_1 = out[:,0]\n",
    "            for i,value in enumerate(out_1) :\n",
    "                if value > 0.5 :\n",
    "                    out_1[i] = 1\n",
    "                else : out_1[i] = 0\n",
    "            pred = out_1  # Use the class with highest probability.\n",
    "            correct += int((pred == data_target).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(v_loaderB.dataset)  # Derive ratio of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06998410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(gnn_model, learning_rate, optimizer_type, weight_decay=1e-4):\n",
    "    if optimizer_type==1:\n",
    "        optimizer = torch.optim.SGD(gnn_model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    if optimizer_type==2:\n",
    "        optimizer = torch.optim.Adam(gnn_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    if optimizer_type ==3 :\n",
    "        optimizer = torch.optim.Adamax(gnn_model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4)\n",
    "        \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef904706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelB(torch.nn.Module):\n",
    "    def __init__(self, input_features, output_features,dropout_rateB1,dropout_rateB2,dropout_rateB3,  \n",
    "                 dense_layer1,dense_layer2, dense_layer3):\n",
    "        super(modelB, self).__init__()\n",
    "        self.lin1 = nn.Linear(input_features,dense_layer1)\n",
    "      \n",
    "        self.lin2 = nn.Linear(int(dense_layer1), dense_layer2)\n",
    "        self.lin3 = nn.Linear(int(dense_layer2), dense_layer3)\n",
    "        self.lin4 = nn.Linear(int(dense_layer3), output_features)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(int(dense_layer1))\n",
    "        self.bn2 = nn.BatchNorm1d(int(dense_layer2))\n",
    "        self.bn3 = nn.BatchNorm1d(int(dense_layer3))\n",
    "        self.dropoutB1 = dropout_rateB1\n",
    "        self.dropoutB2 = dropout_rateB2\n",
    "        self.dropoutB3 = dropout_rateB3\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.bn1(x)\n",
    "       \n",
    "        x = F.dropout(x, p= self.dropoutB1, training=self.training)\n",
    "        x = x.relu()\n",
    "  #      \n",
    "        x = self.lin2(x)\n",
    "        x = self.bn2(x)   \n",
    "        x = F.dropout(x, p= self.dropoutB2, training=self.training)\n",
    "        x = x.relu()\n",
    "  #      \n",
    "        x = self.lin3(x)\n",
    "        x = self.bn3(x)   \n",
    "        x = F.dropout(x, p= self.dropoutB3, training=self.training)\n",
    "\n",
    "        x = x.relu()\n",
    "        x = self.lin4(x)\n",
    "        return torch.sigmoid(x)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a536be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_param_d = {'dropout_rateB1': 0.19029920767006717,\n",
    "               'dropout_rateB2': 0.12142154817498285,\n",
    "               'dropout_rateB3': 0.30892320125476364,\n",
    "               'dense_layer1'  : 180,\n",
    "               'dense_layer2'  : 96,\n",
    "               'dense_layer3'  : 40,\n",
    "               'learning_rate' : 0.00014475405687104653,\n",
    "               'weight_decay'  : 0.0001839631656485908}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b37db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the combined model \n",
    "k =10\n",
    "list_modelA = []\n",
    "list_modelB = []\n",
    "list_modelC = []\n",
    "\n",
    "# load model B\n",
    "for i in range(k):\n",
    "    \n",
    "    input_features    = 166 # length of feature data vector \n",
    "    output_features   = 1\n",
    "    \n",
    "    dropout_rateB1 =hyper_param_d['dropout_rateB1']\n",
    "    dropout_rateB2 =hyper_param_d['dropout_rateB2']\n",
    "    dropout_rateB3 =hyper_param_d['dropout_rateB3']\n",
    "    dense_layer1 = hyper_param_d['dense_layer1']\n",
    "    dense_layer2 = hyper_param_d['dense_layer2']\n",
    "    dense_layer3 = hyper_param_d['dense_layer3']\n",
    " \n",
    "        \n",
    "    model_b= modelB(input_features, output_features,dropout_rateB1,dropout_rateB2,dropout_rateB3,  \n",
    "                 dense_layer1,dense_layer2, dense_layer3)\n",
    "    PATH = '0.39289model_fingerp'+ str(i)+'.pth'\n",
    "    model_b.load_state_dict(torch.load(PATH))\n",
    "    \n",
    "    list_modelB.append(model_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12b2d747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\toxpred\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "nCV= 10 # ten crossfold validation \n",
    "list_fold_pred =[]\n",
    "list_fold_targets =[]\n",
    "\n",
    "\n",
    "v_test_loaderB = V_Loader(dataset = final_clean_fingerp_test, batch_size = 1)\n",
    "v_test_target = V_Loader(dataset = total_test_targets, batch_size = 1)\n",
    "\n",
    "for combined_model in list_modelB:  \n",
    "    list_pred, list_targets = test_1(v_test_loaderB,v_test_target,combined_model)\n",
    "    list_fold_pred.append(list_pred)\n",
    "    list_fold_targets.append(list_targets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3846eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69517"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GET THE PERFORMANCES FROM THE TEST\n",
    "#========================================================================\n",
    "total_performances = performances(list_fold_pred, list_fold_targets, nCV)\n",
    "list_bal_acc = []\n",
    "for sen, spec in zip (total_performances[1] , total_performances[2]):\n",
    "    bal_acc = (sen + spec)/2\n",
    "    list_bal_acc.append(bal_acc)\n",
    "                \n",
    "statistics.mean(list_bal_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4be06a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+-------+-------+-------+-------+-------+---------+---------+-----------+-------+\n",
      "|   Model Name   | Data Type | m_ACC |  m_SN |  m_SP | m_MCC | m_AUC | m_Kappa | m_AUROC | m_Bal_ACC |  m_F1 |\n",
      "+----------------+-----------+-------+-------+-------+-------+-------+---------+---------+-----------+-------+\n",
      "| Test Perf.FCNN |   MACCS   |  0.74 | 0.814 | 0.577 | 0.393 | 0.744 |  0.392  |  0.744  |   0.695   | 0.811 |\n",
      "+----------------+-----------+-------+-------+-------+-------+-------+---------+---------+-----------+-------+\n",
      "+----------------+-----------+-------+-------+-------+-------+-------+---------+---------+-----------+-------+\n",
      "|   Model Name   | Data Type | e_ACC |  e_SN |   SP  | e_MCC | e_AUC | e_Kappa | e_AUROC | e_Bal_ACC |  e_F1 |\n",
      "+----------------+-----------+-------+-------+-------+-------+-------+---------+---------+-----------+-------+\n",
      "| Test Perf.FCNN |   MACCS   | 0.017 | 0.034 | 0.039 | 0.031 | 0.011 |   0.03  |  0.011  |   0.014   | 0.811 |\n",
      "+----------------+-----------+-------+-------+-------+-------+-------+---------+---------+-----------+-------+\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "from prettytable import PrettyTable\n",
    "perf = total_performances\n",
    "model_title = 'Test Perf.FCNN'\n",
    "data_type ='MACCS'\n",
    "Create_Tables(perf, model_title, data_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
